version: 1
disable_existing_loggers: false

formatters:
  standard:
    format: "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
  json:
    format: '{"timestamp": "%(asctime)s", "level": "%(levelname)s", "logger": "%(name)s", "message": "%(message)s", "trace_id": "%(otelTraceID)s", "span_id": "%(otelSpanID)s"}'

handlers:
  console:
    class: logging.StreamHandler
    level: INFO
    formatter: standard
    stream: ext://sys.stdout

  file:
    class: logging.handlers.RotatingFileHandler
    level: INFO
    formatter: standard
    filename: logs/ecommerce_analytics.log
    maxBytes: 10485760 # 10MB
    backupCount: 5
    encoding: utf8

  json_file:
    class: logging.handlers.RotatingFileHandler
    level: INFO
    formatter: json
    filename: logs/ecommerce_analytics.json
    maxBytes: 10485760 # 10MB
    backupCount: 5
    encoding: utf8

  error_file:
    class: logging.handlers.RotatingFileHandler
    level: ERROR
    formatter: json
    filename: logs/error.json
    maxBytes: 10485760 # 10MB
    backupCount: 5
    encoding: utf8

loggers:
  data_generator:
    level: INFO
    handlers: [console, file, json_file, error_file]
    propagate: false

  spark_processor:
    level: INFO
    handlers: [console, file, json_file, error_file]
    propagate: false

  data_mart_processor:
    level: INFO
    handlers: [console, file, json_file, error_file]
    propagate: false

  log_analyzer:
    level: INFO
    handlers: [console, file, json_file, error_file]
    propagate: false

  telemetry:
    level: INFO
    handlers: [console, file, json_file, error_file]
    propagate: false

  database_utils:
    level: INFO
    handlers: [console, file, json_file, error_file]
    propagate: false

  dashboard:
    level: INFO
    handlers: [console, file, json_file, error_file]
    propagate: false

root:
  level: INFO
  handlers: [console, file]
  propagate: true
